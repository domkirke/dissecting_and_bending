{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bending RAVE for neural corrupted audio generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "import os \n",
    "\n",
    "from IPython.display import display, Audio\n",
    "import json \n",
    "import numpy as np\n",
    "import panel as pn\n",
    "pn.extension()\n",
    "import torch\n",
    "torch.set_grad_enabled(False)\n",
    "import torchbend as tb\n",
    "import rave \n",
    " \n",
    "from dandb import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First step : Importing the model and creating data loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before generating audio with RAVE and bending the model's weights/activations, we first need to import the model. For convenience, we will rely on a model which was trained on audios from [the Studio On Line dataset](https://forum.ircam.fr/projects/detail/tinysol/), which contains recordings from a variety of musical instruments. However, all the techniques illustrated in this notebook can be applied to any kind of RAVE, notably models trained using your own datasets ! (more details [here](https://github.com/acids-ircam/RAVE)). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAVE_SAMPLE_RATE = 44100 # the RAVE we'll use was trained using 44.1 kHz audio data\n",
    "\n",
    "with open('paths.json', 'r') as f:\n",
    "    paths = json.load(f)\n",
    "    checkpoint_path = paths['checkpoint_path']\n",
    "    dataset_path = paths['data_path']\n",
    "\n",
    "# Create the model\n",
    "rave_model = load_rave(checkpoint_path)\n",
    "\n",
    "# Create the data loader, which is basically a container for your audio samples\n",
    "audio_loader = make_loader(dataset_path, bs=8, num_workers=8)\n",
    "x = next(iter(audio_loader))\n",
    "x_rec = rave_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for audio_example, reconstructed_audio_example, _ in zip(x.squeeze().numpy(), x_rec.squeeze().numpy(), range(4)):\n",
    "    print('Original audio')\n",
    "    display(Audio(data=audio_example, rate=RAVE_SAMPLE_RATE))\n",
    "    print('Reconstructed audio')\n",
    "    display(Audio(data=reconstructed_audio_example, rate=RAVE_SAMPLE_RATE))\n",
    "    print('='*32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second step : creating and exploiting a bended RAVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bended_rave = tb.BendedModule(rave_model)\n",
    "bended_rave.trace(x=x)\n",
    "print('You may now bend RAVE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting activations and computing activations similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rave_activations = extract_activations(\n",
    "    bended_rave, \n",
    "    RAVE_DECODER_ACT_NAMES, \n",
    "    audio_loader, \n",
    "    avg_batch=True, \n",
    "    max_batches=20\n",
    ")\n",
    "activations_similarity = compute_activations_similarity(\n",
    "    rave_activations\n",
    ")\n",
    "\n",
    "activations_clusters = compute_clusters(\n",
    "    activations_similarity, \n",
    "    threshold=0.75\n",
    ")\n",
    "\n",
    "activations_clusters = compute_non_singleton_clusters(\n",
    "    activations_clusters\n",
    ")\n",
    "activations_clusters = sort_clusters(activations_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating bending callbacks and finally applying those to RAVE intermediate activations !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "affine_benders = make_affine_bending_modules(RAVE_DECODER_ACT_NAMES)\n",
    "clustered_affine_benders = make_clustered_bending_callbacks(\n",
    "    affine_benders, \n",
    "    activations_clusters\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_widgets = make_widgets(RAVE_DECODER_ACT_NAMES)\n",
    "update_bending_params = partial(\n",
    "    update_affine_params, \n",
    "    clustered_affine_cb=clustered_affine_benders\n",
    ")\n",
    "\n",
    "def _bend_rave(\n",
    "    bended_rave_model, \n",
    "    audio_batch, \n",
    "    audio_batch_rec, \n",
    "    **params\n",
    "):\n",
    "    bending_callbacks = update_bending_params(\n",
    "        **params)\n",
    "    bended_audios = get_bended_rave_audios(\n",
    "        audio_batch, \n",
    "        bended_rave_model, \n",
    "        bending_callbacks, \n",
    "    )\n",
    "    audio_grid = make_audio_grid(audio_batch_rec, \n",
    "                                 bended_audios, \n",
    "                                 sr=RAVE_SAMPLE_RATE, \n",
    "                                 ncols=3)\n",
    "    return audio_grid\n",
    "\n",
    "def make_widget_box(op_names, **widgets):\n",
    "    widget_boxes = {op_name: [] for op_name in op_names}\n",
    "    for widget_name, widget in widgets.items():\n",
    "        op_name = widget_name.split('/')[0]\n",
    "        widget_boxes[op_name].append(widget)\n",
    "    return pn.Row(*[pn.WidgetBox(*op_widget) for op_widget in widget_boxes.values()])\n",
    "    \n",
    "\n",
    "bend_rave = partial(_bend_rave, \n",
    "                    bended_rave_model=bended_rave, \n",
    "                    audio_batch=x, \n",
    "                    audio_batch_rec=x_rec)\n",
    "\n",
    "dynamic_bend_rave = pn.bind(bend_rave, \n",
    "                            **op_widgets)\n",
    "pn.Column(\n",
    "    make_widget_box(RAVE_DECODER_ACT_NAMES, **op_widgets), \n",
    "    dynamic_bend_rave\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
