{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring RAVE in Python\n",
    "\n",
    "\n",
    "\n",
    "## Global architecture of RAVE\n",
    "\n",
    "Remembering our RAVE global architecture\n",
    "\n",
    "![RAVE](assets/rave_simple.png)\n",
    "\n",
    "we have different parts : \n",
    "- an *encoder*, that encodes a given audio signal into a time series of *latent* representation\n",
    "- a *decoder*, that decodes a time series of latent representations into an audio signal\n",
    "\n",
    "in addition to this couple of modules (called an *auto-encoder* for the reminder), RAVE also has a *discriminator*, that is used during training to refine the auto-encoder.\n",
    "\n",
    "How are called these modules in the RAVE object? Quite simply, we're not that mischievous. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchbend; print(torchbend.__file__)\n",
    "from dandb import download_models, import_model\n",
    "\n",
    "models = download_models()\n",
    "print(\"downloaded models :\", models)\n",
    "\n",
    "# just take the first model\n",
    "current_model = models[\"sol_full_nopqmf\"]\n",
    "model = import_model(current_model)\n",
    "\n",
    "encoder = model.encoder\n",
    "decoder = model.decoder \n",
    "discriminator = model.discriminator\n",
    "\n",
    "print('encoder type : ', encoder)\n",
    "print('decoder type : ', decoder)\n",
    "print('discriminator type : ', discriminator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here these three modules are instances of our `BendingModule` bending wrapper, but you can recover the actual original modules by accessing the `module` attribute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# /!\\ executing that will output a huge load of text with all the encoder architecture\n",
    "# maybe not a good idea for manic sensibilities\n",
    "# still want it? uncomment the line below\n",
    "\n",
    "# print(model.encoder.module)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, let's now reconstruct a given sound. The most straightforward way is to use the `forward` function, that in our case encodes and decodes an incoming signal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys; sys.path.append('../torchbend')\n",
    "import torchaudio\n",
    "from dandb import get_sounds, plot_audio\n",
    "\n",
    "# load default sounds\n",
    "sounds = get_sounds()\n",
    "x = sounds.load('violin.wav', sr=model.sample_rate)\n",
    "\n",
    "# you can also load sounds from a target folder with a custom path : \n",
    "# sounds = get_sounds(...yourpath...)\n",
    "# print(sounds)\n",
    "# x, sr = sounds.load(...yourfiles...)\n",
    "\n",
    "print('total shape of input tensor (n_examples x n_channels x n_samples):')\n",
    "print(x.shape)\n",
    "\n",
    "out = model.forward(x)\n",
    "for i in range(len(out)):\n",
    "    plot_audio(x[i], name=\"original sample %d\"%i)\n",
    "    plot_audio(out[i], name=\"reconstruction %d\"%i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now extract the latent trajectories of a RAVE model. These can be obtained for a set of sounds (here the tensor `x`) using the function `encode` of the model, as below.\n",
    "\n",
    "***Tip***: you can display a single curve by double-clicking a curve on the legend to the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dandb import plot_latent_trajs\n",
    "\n",
    "z = model.encode(x)\n",
    "plot_latent_trajs(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We visualize here the **full** latent space, with all the 128 dimensions : we can see that most of the latent positions lie between -3 and 3, as the latent space is regularized to resemble an isotropic Gaussian ($\\mu = 0, \\sigma=1)$: \n",
    "\n",
    "![normal distribution](assets/normal.png)\n",
    "\n",
    "We can also see that the latent trajectories are about 621 steps, that corresponds roughly to 1273970 / 2048 (the first value being the length of the sample, and the second the downsampling rate of a casual RAVE). We can invert this full representation by *decoding* this latent series back into audio domain with the `decode` callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dandb import plot_audio\n",
    "reconstructions = model.decode(z)\n",
    "for rec in reconstructions: \n",
    "    plot_audio(rec, display=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compressed vs full latent space\n",
    "\n",
    "When interacting with RAVE through the VST or the nn~ external, recmind that you are not directly enteracting with this 128-dimensional latent space but with a reduced latent, that has a number a dimensions that is specified when exporting the raw RAVE model as a compressed `.ts` file. This intermediary representation is obtained with [Principal Component Analysis](https://en.wikipedia.org/wiki/Principal_component_analysis), that has the nice property that it allows you to recover the amount of reduced dimensions needed to \"reconstruct\" the original space with a given fidelity (given in %). If the PCA has the same amount of dimensions than the original space (here 128), the **reconstruction is lossless**, such that full recover of the latent space is possible.\n",
    "\n",
    "The following code show the fidelity curve (that is, the number of dimensions needed to reconstruct a given percentage of the original dataset) of the loaded model. If you want to obtain the reduced latent space using the model, you can you the `processed` keyword (only available through RAVE's `torchbend` interface)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import plotly.express as px \n",
    "\n",
    "target_fidelity = np.linspace(0., 1., 100, endpoint=False)\n",
    "n_dims_for_fidelity = map(model.get_dims_for_fidelity, target_fidelity)\n",
    "fig = px.line({\"% fidelity\": target_fidelity,'latent dims': n_dims_for_fidelity}, x=\"% fidelity\", y=\"latent dims\", title=\"number of dimensions for target fidelity %\")\n",
    "fig.show()\n",
    "\n",
    "# the latent variables will be projected onto the PCA space when postprocess = True\n",
    "z = model.encode(x, postprocess=True)\n",
    "x = model.decode(z, preprocess=True)\n",
    "\n",
    "# the PCA is not cropped yet, such that the obtained space is lossless.\n",
    "# let's recover the latent trajectories needed to recover 80% of the fidelity : \n",
    "target_fidelity = 0.8\n",
    "n_dims = model.get_dims_for_fidelity(target_fidelity)\n",
    "\n",
    "# and crop the latent representation to the obtained number of dimensions\n",
    "z_reduced = z[..., :n_dims, :]\n",
    "plot_latent_trajs(z_reduced)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using python code to interact with latent space allow modifications that are not possible with a compressed latent space, but... things are little chaotic. Yet, you can have some fun by trying things out :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "sounds = get_sounds()\n",
    "x = sounds.load('violin.wav', 'piano.wav', sr=model.sample_rate)\n",
    "z = model.encode(x)\n",
    "\n",
    "# remember : latent shapes are n_examples x latent_channels x latent_steps\n",
    "print(z.shape)\n",
    "\n",
    "# Zeroing odd dimensions\n",
    "z1 = z.clone()\n",
    "z1[..., 1::2, :] = 0\n",
    "\n",
    "# Progressively noising even dimensions\n",
    "z2 = z.clone()\n",
    "z2[..., ::2, :] = torch.linspace(0, 1, z.shape[-1]) * torch.randn_like(z1[..., ::2, :])\n",
    "\n",
    "# Morphing two latent trajectories through time\n",
    "z3 = (z[0] * torch.linspace(0, 1, z.shape[-1]) + z[1] * torch.linspace(1, 0, z.shape[-1]))[None]\n",
    "\n",
    "# Interleaving two latent trajectories \n",
    "z4 = torch.stack([z[0, i, :] if i % 2 == 0 else z[1, i, :] for i in range(z.shape[1])], 0)[None]\n",
    "\n",
    "# 128-d spherical latent trajectory\n",
    "phase = torch.linspace(0, 1, z1.shape[-1])\n",
    "z5 = torch.cos(2 * torch.pi * (phase[None] + torch.linspace(0, 1, 128)[:, None]))[None]\n",
    "\n",
    "names = ['original', 'zeros', 'progressive noise', \"morphing\", \"interleaving\", \"spherical\"]\n",
    "for i, example in enumerate([z, z1, z2, z3, z4, z5]):\n",
    "    out = model.decode(example)\n",
    "    for j in range(len(out)):\n",
    "        print(f\"{names[i]}_{j}\")\n",
    "        plot_audio(out[j], name=f\"{names[i]}_{j}\", display=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, you started messing around with latent trajectories through Python. Of course, using a programming language removes the cumbersomeness of dealing with 128 dimensions, hence allowing to perform operations directly in the full latent space of RAVE. In the next textbook, we will learn how to analyze the graph of a module, and dissect both encoder and decoders."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
